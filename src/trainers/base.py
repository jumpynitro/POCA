"""
B = batch size
Cl = number of classes
F = number of features
K = number of model samples
N = number of examples
N_t = number of target examples
L   = number of samples_generated by the LLM
"""

import math
import torch
from numpy.random import Generator
from src.math import count_correct, logmeanexp, nll_loss_from_probs
from src.uncertainty import (
    bald_from_logprobs,
    bald_from_probs,
    epig_from_logprobs,
    epig_from_logprobs_using_matmul,
    epig_from_logprobs_using_weights,
    epig_from_probs,
    epig_from_probs_using_matmul,
    epig_from_probs_using_weights,
    marginal_entropy_from_logprobs,
    marginal_entropy_from_probs,
    bald_po_from_logprobs,
    bald_po_from_probs
)
from src.utils import Dictionary, get_float_in_string
from src.uncertainty.utils import (
    margin_prob,
    margin_logprob,
    least_conf_prob,
    least_conf_logprob,
    meanstd_prob,
    meanstd_logprob,
    marginal_entropy_probs,
    marginal_entropy_logprobs
)
from torch import Tensor
from torch.nn.functional import nll_loss
from torch.utils.data import DataLoader
from tqdm import tqdm
from typing import List, Tuple
import re


class Trainer:
    def __init__(self) -> None:
        pass

    def eval_mode(self) -> None:
        pass

    def conditional_predict(self, inputs: Tensor, n_model_samples: int, independent: bool) -> None:
        pass

    def marginal_predict(self, inputs: Tensor, n_model_samples: int) -> None:
        pass

    def evaluate(self, inputs: Tensor, labels: Tensor, n_model_samples: int) -> None:
        pass

    def train(self, train_loader: DataLoader, val_loader: DataLoader) -> None:
        pass

    def test(self, loader: DataLoader) -> Tuple[Tensor, Tensor]:
        self.eval_mode()
        total_correct = total_loss = n_examples = 0

        for batch in loader:
            n_correct, loss = self.evaluate(batch['inputs'], batch['targets'], self.n_samples_test)  # [1,], [1,]
            total_correct += n_correct  # [1,]
            total_loss += loss * len(batch['inputs'])  # [1,]
            n_examples += len(batch['inputs'])  # [1,]

        acc = total_correct / n_examples  # [1,]
        loss = total_loss / n_examples  # [1,]
        return acc, loss  # [1,], [1,]

    def estimate_uncertainty(
        self,
        pool_loader: DataLoader,
        batch_target_inputs,
        mode: str,
        rng: Generator,
        epig_probs_target: List[float] = None,
        epig_probs_adjustment: List[float] = None,
        epig_using_matmul: bool = False,
        features_idx_unobs: Tensor = None,
        num_subset_pool: int = 20,
        use_mask = False,
        dumb_imput = False
    ) -> Dictionary:
        
        # import pdb
        # pdb.set_trace()
        pool_loader = tqdm(pool_loader, desc = "Uncertainty") if self.verbose else pool_loader
        if mode == "bald":
            scores = self.estimate_bald(pool_loader, use_mask = dumb_imput)

        elif "bald-po-feature" in mode:
            scores = self.estimate_bald_po_feature(pool_loader, features_idx_unobs, num_subset_pool, mode)

        elif "bald-po" in mode:
            scores = self.estimate_bald_po(pool_loader, mode)

        elif mode == "epig":
            # if epig_probs_target != None:
            #     scores = self.estimate_epig_using_pool(
            #         pool_loader, epig_probs_target, epig_probs_adjustment, len(target_inputs)
            #     )
            # else:
            scores = self.estimate_epig(pool_loader, batch_target_inputs, epig_using_matmul, use_mask = dumb_imput)
        
        elif "epig-po" in mode:
            scores = self.estimate_epig_po(pool_loader, batch_target_inputs, epig_using_matmul, mode)

        # elif mode == "marg_entropy":
        #     scores = self.estimate_marginal_entropy(pool_loader)

        elif mode in ['margin', 'least_conf', 'meanstd', "marginal_entropy", 'margin-po', 'least_conf-po', 'meanstd-po', "marginal_entropy-po"]:
            scores = self.estimate_common_baseline(pool_loader, mode, use_mask)
            #scores = self.estimate_margin(pool_loader)

        elif mode == "random":
            scores = self.sample_uniform(pool_loader, rng)


        #import pdb
        #pdb.set_trace()
        return scores

    def estimate_common_baseline(self, loader: DataLoader, mode, use_mask) -> Dictionary:
        self.eval_mode()
        scores = Dictionary()
        for batch in loader:
            if '-po' in mode:
                these_scores = self.estimate_common_baseline_minibatch(batch['inputs'], batch['gen_unobs'], mode, 
                                                mask_inputs = batch['mask_inputs'] if 'mask_inputs' in batch.keys() else None)  # [B,]         
            else:
                input_used = batch['inputs']
                if use_mask:
                    input_used = batch['mask_inputs'] * input_used + (1 - batch['mask_inputs']) * batch['gen_unobs']
                    
                these_scores = self.estimate_common_baseline_minibatch(input_used, None, mode, None)  # [B,]
        scores.append({mode: these_scores.cpu()})
        return scores.concatenate()

    def estimate_common_baseline_minibatch(self, inputs: Tensor, gen_unobs: Tensor, mode: str, mask_inputs: bool = None) -> None:
        pass

    def estimate_marginal_entropy(self, loader: DataLoader) -> Dictionary:
        self.eval_mode()
        scores = Dictionary()

        for batch in loader:
            marg_entropy_scores = self.estimate_marginal_entropy_minibatch(batch['inputs'])  # [B,]
            scores.append({"marg_entropy": marg_entropy_scores.cpu()})

        return scores.concatenate()

    def estimate_marginal_entropy_minibatch(self, inputs: Tensor) -> None:
        pass

    def estimate_bald(self, loader: DataLoader, use_mask = False) -> Dictionary:
        self.eval_mode()
        scores = Dictionary()

        for batch in loader:
            input_used = batch['inputs']
            if use_mask:
                input_used = batch['mask_inputs'] * input_used + (1 - batch['mask_inputs']) * batch['gen_unobs']
            bald_scores = self.estimate_bald_minibatch(input_used)  # [B,]
            scores.append({"bald": bald_scores.cpu()})

        return scores.concatenate()

    def estimate_bald_minibatch(self, inputs: Tensor) -> None:
        pass

    def estimate_bald_po(self, loader: DataLoader, mode: str) -> Dictionary:
        self.eval_mode()
        scores = Dictionary()
        
        for batch in loader:
            bald_po_scores = self.estimate_bald_po_minibatch(batch['inputs'], batch['gen_unobs'], mode, 
                    mask_inputs        = batch['mask_inputs'] if 'mask_inputs' in batch.keys() else None)  # [B,]
            scores.append({key: bald_po_scores[key].cpu() for key in bald_po_scores.keys()})
            #scores.append({"bald-po": bald_po_scores.cpu()})

        return scores.concatenate()
    
    def estimate_bald_po_feature(self, loader: DataLoader, features_idx_unobs: Tensor, num_subset_pool:int, mode: str) -> Dictionary:
        self.eval_mode()
        scores = Dictionary()
        
        for batch in loader:
            bald_po_scores = self.estimate_bald_po_feature_minibatch(batch['inputs'], batch['gen_unobs'],
                                    features_idx_unobs, num_subset_pool, mode,
                                    cost_inputs        = batch['cost_inputs'] if 'cost_inputs' in batch.keys() else None,
                                    mask_inputs        = batch['mask_inputs'] if 'mask_inputs' in batch.keys() else None,
                                    mask_inputs_normal = batch['mask_inputs_normal'] if 'mask_inputs_normal' in batch.keys() else None)  # [B,]
            all_scores = {key: bald_po_scores[key].cpu() for key in bald_po_scores.keys()}
            # if 'cost' in batch:
            #     all_scores['cost'] = batch['cost']
            scores.append(all_scores)
            #scores.append({"bald-po": bald_po_scores.cpu()})
            
        return scores.concatenate()
    
    def estimate_bald_po_minibatch(self, inputs: Tensor) -> None:
        pass

    def estimate_bald_po_feature_minibatch(self, inputs: Tensor) -> None:
        pass

    def estimate_epig(
        self, loader: DataLoader, batch_target_inputs: Tensor, use_matmul: bool, use_mask = False
    ) -> Dictionary:
        self.eval_mode()
        scores = Dictionary()
        for batch in loader:
            input_used = batch['inputs']
            if use_mask:
                input_used = batch['mask_inputs'] * input_used + (1 - batch['mask_inputs']) * batch['gen_unobs']
            epig_scores = self.estimate_epig_minibatch(input_used, batch_target_inputs, use_matmul = use_matmul)  # [B,]
            scores.append({"epig": epig_scores.cpu()})

        return scores.concatenate()
    
    def estimate_epig_po(
        self, loader: DataLoader, batch_target_inputs: Tensor, use_matmul: bool, mode: str
    ) -> Dictionary:
        self.eval_mode()
        scores = Dictionary()

        for batch in loader:
            #inputs: Tensor, batch_target_inputs: Tensor, gen_unobs: Tensor, mode: str, mask_inputs: bool = None, use_matmul: bool = False
            epig_scores = self.estimate_epig_po_minibatch(batch['inputs'], batch_target_inputs, batch['gen_unobs'], mode,
                                                       mask_inputs = batch['mask_inputs'] if 'mask_inputs' in batch.keys() else None,
                                                       use_matmul = use_matmul)  # [B,]
            scores.append({mode: epig_scores.cpu()})

        return scores.concatenate()
    def estimate_epig_minibatch(
        self, inputs: Tensor, target_inputs: Tensor, use_matmul: bool,
    ) -> None:
        pass

    def estimate_epig_po_minibatch(
        self, inputs: Tensor, batch_target_inputs: Tensor, gen_unobs: Tensor, mode: str, mask_inputs: bool = None, use_matmul: bool = False,
    ) -> None:
        pass
    

    def estimate_epig_using_pool(
        self,
        loader: DataLoader,
        probs_target: List[float],
        probs_adjustment: List[float],
        n_input_samples: int,
    ) -> None:
        pass

    def sample_uniform(self, loader: DataLoader, rng: Generator) -> Dictionary:
        n_inputs = len(loader.dataset.indices)
        samples = rng.uniform(size=n_inputs)
        samples = torch.tensor(samples)
        scores = Dictionary()
        scores.append({"random": samples})
        return scores.concatenate()


class LogProbsTrainer(Trainer):
    """
    Base trainer for a model that outputs log probabilities.
    """

    def evaluate(
        self, inputs: Tensor, labels: Tensor, n_model_samples: int
    ) -> Tuple[Tensor, Tensor]:
        logprobs = self.marginal_predict(inputs, n_model_samples)  # [N, Cl]
        n_correct = count_correct(logprobs, labels)  # [1,]
        loss = nll_loss(logprobs, labels)  # [1,]
        return n_correct, loss

    def estimate_common_baseline_minibatch(self, inputs: Tensor, mode):
        logprobs = self.conditional_predict(
            inputs, self.n_samples_test, independent=True
        )  # [N, K, Cl]
        if mode == 'margin':
            return margin_logprob(logprobs)  # [N,]
        elif mode == 'least_conf':
            return least_conf_logprob(logprobs)  # [N,]
        elif mode == 'meanstd':
            return meanstd_logprob(logprobs)  # [N,]
        elif mode == 'marginal_entropy':
            return marginal_entropy_logprobs(logprobs)  # [N,]

    def estimate_marginal_entropy_minibatch(self, inputs: Tensor) -> Tensor:
        logprobs = self.conditional_predict(
            inputs, self.n_samples_test, independent=True
        )  # [N, K, Cl]
        return marginal_entropy_from_logprobs(logprobs)  # [N,]

    def estimate_bald_minibatch(self, inputs: Tensor) -> Tensor:

        logprobs = self.conditional_predict(
            inputs, self.n_samples_test, independent=True
        )  # [N, K, Cl]
        return bald_from_logprobs(logprobs)  # [N,]
    
    # def estimate_bald_po_minibatch(self, inputs: Tensor, gen_unobs: Tensor = None, mode: str = '', mask_inputs: bool = None) -> Tensor:
    #     mc_samples   = gen_unobs.shape[1]
    #     all_probs = []
    #     for idx in range(mc_samples):
    #         gen_unobs_used = gen_unobs[:, idx, :] if len(gen_unobs.shape) == 3 else gen_unobs[idx, :] 
    #         inputs_used = torch.cat([inputs, gen_unobs_used], axis = -1) if mask_inputs is None else mask_inputs * inputs + (1 - mask_inputs) * gen_unobs_used
    #         all_probs += [self.conditional_predict(inputs_used, self.n_samples_test, independent=True)]  # [N, K, Cl]
    #     all_probs = torch.stack(all_probs, axis = 1) # [N, G, K, Cl]
    #     return bald_po_from_logprobs(all_probs, mode)  # [N,]


    def estimate_bald_po_minibatch(self, inputs: Tensor, gen_unobs: Tensor, mode: str, mask_inputs: bool = None) -> Tensor:
        mc_samples   = gen_unobs.shape[1]
        if torch.sum(torch.isinf(gen_unobs)).item() > 0:
            gen_unobs[torch.isinf(gen_unobs)] = 0
        #all_probs = []

        if mode == 'bald-po-bald-marginalized':
            all_logprobs_data   = []
        else:
            all_metrics_data = []

        for idx in range(mc_samples):
            gen_unobs_used = gen_unobs[:, idx, :] if len(gen_unobs.shape) == 3 else gen_unobs[idx, :]
            inputs_used = torch.cat([inputs, gen_unobs_used], axis = -1) if mask_inputs is None else mask_inputs * inputs + (1 - mask_inputs) * gen_unobs_used
            logprob = self.conditional_predict(inputs_used, self.n_samples_test, independent=True)  # [N, K, Cl]
            if mode ==  'bald-po-bald-marginalized':
                all_logprobs_data += [logprob]
            else:
                all_metrics_data   += [bald_from_logprobs(logprob)] 

        if mode == 'bald-po-bald-marginalized':
            #all_logprobs_data = torch.stack(all_logprobs_data, axis = 1).exp().mean(1).log() # [N, G, K, Cl]
            all_logprobs_data = torch.logsumexp(torch.stack(all_logprobs_data, axis = 1) - torch.log(mc_samples), axis = 1)
            return {"bald-po-bald-marginalized": bald_from_logprobs(all_logprobs_data)}
        else:
            return {"bald-po": torch.stack(all_metrics_data, axis = 1).mean(1)}
            
        #scores_this_round[index_flt] = torch.min(scores_this_round[index_flt], scores_used_aux)
        # [N, G, K, Cl]

    def estimate_epig_minibatch(
        self, inputs: Tensor, target_inputs: Tensor, use_matmul: bool
    ) -> Tensor:
        combined_inputs = torch.cat((inputs, target_inputs))  # [N + N_t, ...]
        logprobs = self.conditional_predict(
            combined_inputs, self.n_samples_test, independent=False
        )  # [N + N_t, K, Cl]
        epig_fn = epig_from_logprobs_using_matmul if use_matmul else epig_from_logprobs
        return epig_fn(logprobs[: len(inputs)], logprobs[len(inputs) :])  # [N,]
    
    # def estimate_epig_po_minibatch(
    #     self, inputs: Tensor, target_inputs: Tensor, use_matmul: bool
    # ) -> Tensor:
    #     combined_inputs = torch.cat((inputs, target_inputs))  # [N + N_t, ...]
    #     logprobs = self.conditional_predict(
    #         combined_inputs, self.n_samples_test, independent=False
    #     )  # [N + N_t, K, Cl]
    #     epig_fn = epig_from_logprobs_using_matmul if use_matmul else epig_from_logprobs
    #     return epig_fn(logprobs[: len(inputs)], logprobs[len(inputs) :])  # [N,]




    def estimate_epig_po_minibatch(
        self, inputs: Tensor, batch_target_inputs: Tensor, gen_unobs: Tensor, mode: str, mask_inputs: bool = None, use_matmul: bool = False
    ) -> Tensor:

        epig_fn = epig_from_logprobs_using_matmul if use_matmul else epig_from_logprobs
        target_inputs       = batch_target_inputs['inputs']
        target_gen_unobs    = batch_target_inputs['gen_unobs']
        target_mask_inputs  = batch_target_inputs['mask_inputs'] if 'mask_inputs' in batch_target_inputs.keys() else None
        mc_samples          = gen_unobs.shape[1]

        all_logprobs_target = []
        for idx in range(mc_samples):
            target_gen_unobs_used = target_gen_unobs[:, idx, :] if len(target_gen_unobs.shape) == 3 else target_gen_unobs[idx, :]
            target_inputs_used    = torch.cat([target_inputs, target_gen_unobs_used], axis = -1) if mask_inputs is None else \
                                                target_mask_inputs * target_inputs + (1 - target_mask_inputs) * target_gen_unobs_used
            all_logprobs_target += [self.conditional_predict(target_inputs_used, self.n_samples_test, independent=True)]
        #logprob_target =  torch.stack(all_logprobs_target, axis = 1).exp().mean(1).log()
        logprob_target =  torch.logsumexp(torch.stack(all_logprobs_target, axis = 1) - torch.log(mc_samples), axis = 1)

        if mode == 'epig-po-epig-marginalized':
            all_logprobs_data   = []
        else:
            all_metrics_data = []
        for idx in range(mc_samples):
            gen_unobs_used = gen_unobs[:, idx, :] if len(gen_unobs.shape) == 3 else gen_unobs[idx, :]
            inputs_used = torch.cat([inputs, gen_unobs_used], axis = -1) if mask_inputs is None else mask_inputs * inputs + (1 - mask_inputs) * gen_unobs_used
            logprob = self.conditional_predict(inputs_used, self.n_samples_test, independent=True)
            if mode == 'epig-po-epig-marginalized':
                all_logprobs_data   += [logprob]
            else:
                all_metrics_data += [epig_fn(logprob, logprob_target)]          
            # [N, K, Cl]
        if mode == 'epig-po-epig-marginalized':
            #all_logprobs_data = torch.stack(all_logprobs_data, axis = 1).exp().mean(1).log() # [N, G, K, Cl]
            all_logprobs_data = torch.logsumexp(torch.stack(all_logprobs_data, axis = 1) - torch.log(mc_samples), axis = 1)
            return epig_fn(all_logprobs_data, logprob_target)
        else:
            return torch.stack(all_metrics_data, axis = 1).mean(1)




    @torch.inference_mode()
    def estimate_epig_using_pool(
        self,
        loader: DataLoader,
        probs_target: List[float],
        probs_adjustment: List[float] = None,
        n_input_samples: int = None,
    ) -> Dictionary:
        self.eval_mode()

        logprobs_cond = []
        for inputs, _ in loader:
            logprobs_cond_i = self.conditional_predict(
                inputs, self.n_samples_test, independent=True
            )  # [B, K, Cl]
            logprobs_cond.append(logprobs_cond_i)
        logprobs_cond = torch.cat(logprobs_cond)  # [N, K, Cl]

        logprobs_marg = logmeanexp(logprobs_cond, dim=1)  # [N, Cl]
        logprobs_marg_marg = logmeanexp(logprobs_marg, dim=0, keepdim=True)  # [1, Cl]

        if probs_adjustment != None:
            probs_adjustment = torch.tensor([probs_adjustment])  # [1, Cl]
            probs_adjustment = probs_adjustment.to(inputs.device)  # [1, Cl]
            probs_marg = torch.exp(logprobs_marg)  # [N, Cl]
            probs_marg += probs_adjustment * torch.exp(logprobs_marg_marg)  # [N, Cl]
            probs_marg /= torch.sum(probs_marg, dim=-1, keepdim=True)  # [N, Cl]
            logprobs_marg = torch.log(probs_marg)  # [N, Cl]

        # Compute the weights, w(x_*) ~= ∑_{y_*} p_*(y_*) p_{pool}(y_*|x_*) / p_{pool}(y_*).
        probs_target = torch.tensor([probs_target])  # [1, Cl]
        probs_target = probs_target.to(inputs.device)  # [1, Cl]
        log_ratio = logprobs_marg - logprobs_marg_marg  # [N, Cl]
        weights = torch.sum(probs_target * torch.exp(log_ratio), dim=-1)  # [N,]

        # Ensure that ∑_{x_*} w(x_*) == N.
        assert math.isclose(torch.sum(weights).item(), len(weights), rel_tol=1e-3)

        # Compute the weighted EPIG scores.
        scores = Dictionary()

        if n_input_samples != None:
            # We do not need to normalize the weights before passing them to torch.multinomial().
            inds = torch.multinomial(
                weights, num_samples=n_input_samples, replacement=True
            )  # [N_s,]

            logprobs_target = logprobs_cond[inds]  # [N_s, K, Cl]

            for logprobs_cond_i in torch.split(logprobs_cond, len(inputs)):
                epig_scores = epig_from_logprobs(logprobs_cond_i, logprobs_target)  # [B,]
                scores.append({"epig": epig_scores.cpu()})

        else:
            logprobs_target = logprobs_cond  # [N, K, Cl]

            for logprobs_cond_i in torch.split(logprobs_cond, len(inputs)):
                epig_scores = epig_from_logprobs_using_weights(
                    logprobs_cond_i, logprobs_target, weights
                )  # [B,]
                scores.append({"epig": epig_scores.cpu()})

        return scores.concatenate()


class ProbsTrainer(Trainer):
    """
    Base trainer for a model that outputs probabilities.
    """

    def evaluate(
        self, inputs: Tensor, labels: Tensor, n_model_samples: int
    ) -> Tuple[Tensor, Tensor]:
        probs = self.marginal_predict(inputs, n_model_samples)  # [N, Cl]
        n_correct = count_correct(probs, labels)  # [1,]
        loss = nll_loss_from_probs(probs, labels)  # [1,]
        return n_correct, loss

    def estimate_common_baseline_minibatch(self, inputs: Tensor, gen_unobs: Tensor, mode: str, mask_inputs: bool = None):
        mode_aux = mode.replace('-po', '')
        if '-po' in mode:
            mc_samples   = gen_unobs.shape[1]
            if torch.sum(torch.isinf(gen_unobs)).item() > 0:
                gen_unobs[torch.isinf(gen_unobs)] = 0
            all_scores = []
            for idx in range(mc_samples):
                gen_unobs_used = gen_unobs[:, idx, :] if len(gen_unobs.shape) == 3 else gen_unobs[idx, :]
                inputs_used = torch.cat([inputs, gen_unobs_used], axis = -1) if mask_inputs is None else mask_inputs * inputs + (1 - mask_inputs) * gen_unobs_used
                probs = self.conditional_predict(inputs_used, self.n_samples_test, independent=True)  # [N, K, Cl]s
                if mode_aux == 'margin':
                    this_metric = margin_prob(probs)  # [N,]
                elif mode_aux == 'least_conf':
                    this_metric = least_conf_prob(probs)  # [N,]
                elif mode_aux == 'meanstd':
                    return meanstd_prob(probs)  # [N,]
                elif mode_aux == 'marginal_entropy':
                    this_metric = marginal_entropy_probs(probs)
                all_scores += [this_metric]  # [N,]
            return torch.stack(all_scores, axis = 1).mean(1)
        else: 
            probs = self.conditional_predict(
                inputs, self.n_samples_test, independent=True
            )  # [N, K, Cl]
            if mode_aux == 'margin':
                return margin_prob(probs)  # [N,]
            elif mode_aux == 'least_conf':
                return least_conf_prob(probs)  # [N,]
            elif mode_aux == 'meanstd':
                return meanstd_prob(probs)  # [N,]
            elif mode_aux == 'marginal_entropy':
                return marginal_entropy_probs(probs)  # [N,]


    def estimate_marginal_entropy_minibatch(self, inputs: Tensor) -> Tensor:
        probs = self.conditional_predict(
            inputs, self.n_samples_test, independent=True
        )  # [N, K, Cl]
        return marginal_entropy_from_probs(probs)  # [N,]

    def estimate_bald_minibatch(self, inputs: Tensor) -> Tensor:
        probs = self.conditional_predict(
            inputs, self.n_samples_test, independent=True
        )  # [N, K, Cl]
        return bald_from_probs(probs)  # [N,]
    
    def estimate_bald_po_minibatch(self, inputs: Tensor, gen_unobs: Tensor, mode: str, mask_inputs: bool = None) -> Tensor:
        mc_samples   = gen_unobs.shape[1]
        if torch.sum(torch.isinf(gen_unobs)).item() > 0:
            gen_unobs[torch.isinf(gen_unobs)] = 0
        all_probs = []
        for idx in range(mc_samples):
            gen_unobs_used = gen_unobs[:, idx, :] if len(gen_unobs.shape) == 3 else gen_unobs[idx, :]
            inputs_used = torch.cat([inputs, gen_unobs_used], axis = -1) if mask_inputs is None else mask_inputs * inputs + (1 - mask_inputs) * gen_unobs_used
            all_probs += [self.conditional_predict(inputs_used, self.n_samples_test, independent=True)]  # [N, K, Cl]
        all_probs = torch.stack(all_probs, axis = 1) # [N, G, K, Cl]
        if mode == 'bald-po-bald-marginalized':
            return {"bald-po-bald-marginalized": bald_from_probs(all_probs.mean(1)).cpu()}
        else:
            return bald_po_from_probs(all_probs, mode)  # [N,]


    def estimate_bald_po_feature_minibatch(self, inputs: Tensor, gen_unobs: Tensor = None, features_idx_unobs: Tensor = None,
                                    num_subset_pool: int = 5, mode: str = '', cost_inputs = None,
                                    mask_inputs: bool = None, mask_inputs_normal: bool = None) -> Tensor:
        mc_samples = gen_unobs.shape[1]
        dim_unobs_orig, dim_unobs_dummy = features_idx_unobs.shape[0], features_idx_unobs.shape[1]  

        all_logprobs = []
        for idx in range(mc_samples):
            gen_unobs_used = gen_unobs[:, idx, :] if len(gen_unobs.shape) == 3 else gen_unobs[idx, :]
            inputs_used    = torch.cat([inputs, gen_unobs_used], axis = -1) if mask_inputs is None else mask_inputs * inputs + (1 - mask_inputs) * gen_unobs_used
            all_logprobs  += [self.conditional_predict(inputs_used, self.n_samples_test, independent=True)]  # [N, K, Cl]
        all_logprobs = torch.stack(all_logprobs, axis = 1) # [N, G, K, Cl]
        scores = bald_po_from_probs(all_logprobs, mode)  # [N,]
        scores_all_feat = scores[mode]

        use_cost_restriction = True if cost_inputs is not None and not ('uncertainty-cost' in mode) and not 'test' in mode else False
        arange_idx   = torch.arange(len(inputs))
        add_filter   = torch.ones((len(arange_idx), )).bool()
        if not 'test' in mode:
            if num_subset_pool > 0:
                add_filter         = torch.zeros((len(arange_idx), )).bool()
                argidx             = scores_all_feat.argsort()[-num_subset_pool:]
                add_filter[argidx] = True
                copy_add_filter    = add_filter.clone()
                #arange_idx = arange_idx[argidx]
            total_reached = add_filter.sum().item()

            #delta_scores_final_considered = torch.ones((len(arange_idx), )).double() * -9999999
            scores_finished = torch.zeros((len(arange_idx), )).bool()
            mi_epsilon_th   = get_float_in_string(mode)
        else:
            all_scores_considered       = torch.ones((len(arange_idx), dim_unobs_orig)).double() * -9999999
            all_delta_scores_considered = torch.ones((len(arange_idx), dim_unobs_orig)).double() * -9999999
            if cost_inputs is not None:
                all_cost_considered = torch.ones((len(arange_idx), dim_unobs_orig)) * -9999999
            all_feat_considered = torch.ones((len(arange_idx), dim_unobs_orig, dim_unobs_dummy))

        scores_considered  = torch.ones((len(arange_idx), )).double() * -9999999
        if mask_inputs is None:
            feat_considered = torch.ones((len(arange_idx), dim_unobs_dummy)).float()
        else:
            feat_considered = mask_inputs.clone()
        if cost_inputs is not None:
            torch_eye       = torch.eye(dim_unobs_orig).float()
            cost_considered = torch.ones((len(arange_idx), )) * -9999999
            columns_of_ones = torch.ones((len(arange_idx), 1)).float()
            if mask_inputs is None:
                feat_normal_considered = torch.ones((len(arange_idx), dim_unobs_orig)).float()
            else:
                feat_normal_considered = mask_inputs_normal.clone()

            #idx_scores_not_finished = torch.zeros((len(arange_idx), 1)).bool()
        for iter_feat in range(dim_unobs_orig):
            #scores_best_curr = torch.full((len(inputs), ), info.max)
            print("First round")
            delta_scores_best = torch.ones((len(arange_idx), )).double() * 9999999
            scores_best       = torch.ones((len(arange_idx), )).double() * -9999999
            feat_best         = torch.zeros((len(arange_idx), dim_unobs_dummy)).float()
            if cost_inputs is not None:
                feat_normal_best  = torch.zeros((len(arange_idx), dim_unobs_orig)).float()

            if use_cost_restriction:
                #if idx_scores_not_finished is not None:
                #    cost_considered[idx_scores_not_finished] = this_cost[idx_scores_not_finished]
                this_cost = (torch.cat([feat_normal_considered, columns_of_ones], axis = 1) * cost_inputs).sum(1)
                condition = this_cost  <= mi_epsilon_th
                idx_scores_finished     =   condition  * add_filter
                idx_scores_not_finished = (~condition) * add_filter
                scores_finished[idx_scores_finished] = True

            if not 'test' in mode:
                add_filter = add_filter * ~scores_finished

            for idx_feat, feat_array in enumerate(features_idx_unobs):
                index_flt   = ((feat_array * feat_considered).sum(1) > 0) * add_filter# this means we can take out the features
                arange_flt  = arange_idx[index_flt]
                inputs_this = inputs[arange_flt]
                feat_considered_this = feat_considered[arange_flt] - feat_array
                if cost_inputs is not None:
                    feat_normal_considered_this = feat_normal_considered[arange_flt] - torch_eye[idx_feat]
                if mask_inputs is not None:
                    mask_inputs_this = mask_inputs[arange_flt]
                if len(feat_considered_this) > 0:
                    all_logprobs = []
                    for idx_cond in range(mc_samples):
                        gen_cond  = gen_unobs[arange_flt, idx_cond, :] if len(gen_unobs.shape) == 3 else gen_unobs[idx_cond, :] 
                        gen_cond *= feat_considered_this
                        all_logprobs_marginal = []
                        for idx_marg in range(mc_samples):
                            gen_marg  = gen_unobs[arange_flt, idx_marg, :] if len(gen_unobs.shape) == 3 else gen_unobs[idx_marg, :] 
                            gen_marg *= (1 - feat_considered_this)
                            gen_used  = gen_cond + gen_marg

                            inputs_used = torch.cat([inputs_this, gen_used], axis = -1) if mask_inputs is None else \
                                                                mask_inputs_this * inputs_this + (1 - mask_inputs_this) * gen_used
                            all_logprobs_marginal += [self.conditional_predict(inputs_used, self.n_samples_test, independent=True)]  # [N, K, Cl]
                            #all_logprobs_marginal += [self.conditional_predict(torch.cat([inputs_this, gen_used], axis = -1),
                            #                                                    self.n_samples_test, independent=True)]  # [N, K, Cl]
                            
                        all_logprobs += [torch.stack(all_logprobs_marginal, axis = -1).mean(-1)] # [N, K, Cl]
                    all_logprobs = torch.stack(all_logprobs, axis = 1) # [N, G, K, Cl]
                    scores_aux = bald_po_from_probs(all_logprobs, mode)

                    delta_score_aux = scores_all_feat[arange_flt] - scores_aux[mode]
                    idx_delta_scores_better = torch.le(delta_score_aux, delta_scores_best[arange_flt])                    
                    arange_flt_better = arange_flt[idx_delta_scores_better]
                    #print("delta score aux, ", torch.histogram(delta_score_aux, 10))
                    #print("idx delta scores better, ", idx_delta_scores_better.sum())

                    delta_scores_best[arange_flt_better] = delta_score_aux[idx_delta_scores_better]
                    feat_best[arange_flt_better] = feat_considered_this[idx_delta_scores_better]
                    scores_best[arange_flt_better] = scores_all_feat[arange_flt_better]
                    if cost_inputs is not None:
                        feat_normal_best[arange_flt_better] = feat_normal_considered_this[idx_delta_scores_better]

            if cost_inputs is not None:
               this_cost = (torch.cat([feat_normal_best, columns_of_ones], axis = 1) * cost_inputs).sum(1)

            if not 'test' in mode:
                if not use_cost_restriction:
                    condition = delta_scores_best >= mi_epsilon_th
                    idx_scores_finished     =   condition  * add_filter
                    idx_scores_not_finished = (~condition) * add_filter
                    scores_finished[idx_scores_finished] = True
            else:
                idx_scores_not_finished = add_filter
                all_feat_considered[add_filter, iter_feat] = feat_best[add_filter]
                all_scores_considered[add_filter, iter_feat] = scores_best[add_filter]
                all_delta_scores_considered[add_filter, iter_feat] = delta_scores_best[add_filter]
                if cost_inputs is not None:
                    #this_cost = (torch.cat([feat_normal_best, columns_of_ones], axis = 1) * cost_inputs).sum(1)
                    all_cost_considered[add_filter, iter_feat] = this_cost[add_filter] 
                    
            feat_considered[idx_scores_not_finished] = feat_best[idx_scores_not_finished]
            if not 'uncertainty-cost' in mode:
                scores_considered[idx_scores_not_finished] = scores_best[idx_scores_not_finished] 
            else:
                scores_considered[idx_scores_not_finished] = scores_best[idx_scores_not_finished] / this_cost[idx_scores_not_finished]

            if cost_inputs is not None:
                #if idx_scores_not_finished is not None:
                feat_normal_considered[idx_scores_not_finished] = feat_normal_best[idx_scores_not_finished]
                cost_considered[idx_scores_not_finished] = this_cost[idx_scores_not_finished]
            #if cost_inputs is not None:
            #    cost_considered[idx_scores_not_finished] = this_cost[idx_scores_not_finished]

            #delta_scores_final_considered[idx_scores_not_finished] = delta_scores_best[idx_scores_not_finished]

            if not 'test' in mode and scores_finished.sum().item() == total_reached:
                break

        scores[mode] = scores_considered
        scores['features_selected'] = feat_considered
        if cost_inputs is not None:
            scores['cost_selected'] = cost_considered
        if 'test' in mode:
            scores['all_features_considered'] = all_feat_considered
            scores['all_delta_scores_considered'] = all_delta_scores_considered
            scores['all_scores_considered'] = all_scores_considered
            if cost_inputs is not None:
                scores['all_cost_considered'] = all_cost_considered
        return scores

                
    def estimate_epig_minibatch(
        self, inputs: Tensor, batch_target_inputs: Tensor, use_matmul: bool, use_mask = False
    ) -> Tensor:
        target_inputs = batch_target_inputs['inputs']
        if use_mask:
            target_inputs = batch_target_inputs['mask_inputs'] * target_inputs + (1 - batch_target_inputs['mask_inputs']) * batch_target_inputs['gen_unobs']
        _inputs = torch.cat((inputs, target_inputs))  # [N + N_t, ...]
        probs = self.conditional_predict(
            _inputs, self.n_samples_test, independent=False
        )  # [N + N_t, K, Cl]
        epig_fn = epig_from_probs_using_matmul if use_matmul else epig_from_probs
        return epig_fn(probs[: len(inputs)], probs[len(inputs) :])  # [N,]
    
    def estimate_epig_po_minibatch(
        self, inputs: Tensor, batch_target_inputs: Tensor, gen_unobs: Tensor, mode: str, mask_inputs: bool = None, use_matmul: bool = False
    ) -> Tensor:

        epig_fn = epig_from_probs_using_matmul if use_matmul else epig_from_probs 
        target_inputs       = batch_target_inputs['inputs']
        target_gen_unobs    = batch_target_inputs['gen_unobs']
        target_mask_inputs  = batch_target_inputs['mask_inputs'] if 'mask_inputs' in batch_target_inputs.keys() else None
        mc_samples          = gen_unobs.shape[1]

        all_probs_target = []
        for idx in range(mc_samples):
            target_gen_unobs_used = target_gen_unobs[:, idx, :] if len(target_gen_unobs.shape) == 3 else target_gen_unobs[idx, :]
            target_inputs_used    = torch.cat([target_inputs, target_gen_unobs_used], axis = -1) if mask_inputs is None else \
                                                target_mask_inputs * target_inputs + (1 - target_mask_inputs) * target_gen_unobs_used
            all_probs_target += [self.conditional_predict(target_inputs_used, self.n_samples_test, independent=True)]
        prob_target =  torch.stack(all_probs_target, axis = 1).mean(1)

        if mode == 'epig-po-epig-marginalized':
            all_probs_data   = []
        else:
            all_metrics_data = []
        for idx in range(mc_samples):
            gen_unobs_used = gen_unobs[:, idx, :] if len(gen_unobs.shape) == 3 else gen_unobs[idx, :]
            inputs_used = torch.cat([inputs, gen_unobs_used], axis = -1) if mask_inputs is None else mask_inputs * inputs + (1 - mask_inputs) * gen_unobs_used
            prob = self.conditional_predict(inputs_used, self.n_samples_test, independent=True)
            if mode == 'epig-po-epig-marginalized':
                all_probs_data   += [prob]
            else:
                all_metrics_data += [epig_fn(prob, prob_target)]          
            # [N, K, Cl]
        if mode == 'epig-po-epig-marginalized':
            all_probs_data = torch.stack(all_probs_data, axis = 1).mean(1) # [N, G, K, Cl]
            return epig_fn(all_probs_data, prob_target)
        else:
            return torch.stack(all_metrics_data, axis = 1).mean(1)

        target_inputs = batch_target_inputs['inputs']

        _inputs = torch.cat((inputs, target_inputs))  # [N + N_t, ...]
        probs = self.conditional_predict(
            _inputs, self.n_samples_test, independent=False
        )  # [N + N_t, K, Cl]
        epig_fn = epig_from_probs_using_matmul if use_matmul else epig_from_probs
        return epig_fn(probs[: len(inputs)], probs[len(inputs) :])  # [N,]
    

    @torch.inference_mode()
    def estimate_epig_using_pool(
        self,
        loader: DataLoader,
        probs_target: List[float],
        probs_adjustment: List[float] = None,
        n_input_samples: int = None,
    ) -> Dictionary:
        self.eval_mode()

        probs_cond = []
        for inputs, _ in loader:
            probs_cond_i = self.conditional_predict(
                inputs, self.n_samples_test, independent=True
            )  # [B, K, Cl]
            probs_cond.append(probs_cond_i)
        probs_cond = torch.cat(probs_cond)  # [N, K, Cl]

        probs_marg = torch.mean(probs_cond, dim=1)  # [N, Cl]
        probs_marg_marg = torch.mean(probs_marg, dim=0, keepdim=True)  # [1, Cl]

        if probs_adjustment != None:
            probs_adjustment = torch.tensor([probs_adjustment])  # [1, Cl]
            probs_adjustment = probs_adjustment.to(inputs.device)  # [1, Cl]
            probs_marg += probs_adjustment * probs_marg_marg  # [N, Cl]
            probs_marg /= torch.sum(probs_marg, dim=-1, keepdim=True)  # [N, Cl]

        # Compute the weights, w(x_*) ~= ∑_{y_*} p_*(y_*) p_{pool}(y_*|x_*) / p_{pool}(y_*).
        probs_target = torch.tensor([probs_target])  # [1, Cl]
        probs_target = probs_target.to(inputs.device)  # [1, Cl]
        weights = torch.sum(probs_target * probs_marg / probs_marg_marg, dim=-1)  # [N,]

        # Ensure that ∑_{x_*} w(x_*) == N.
        assert math.isclose(torch.sum(weights).item(), len(weights), rel_tol=1e-3)

        # Compute the weighted EPIG scores.
        scores = Dictionary()

        if n_input_samples != None:
            # We do not need to normalize the weights before passing them to torch.multinomial().
            inds = torch.multinomial(
                weights, num_samples=n_input_samples, replacement=True
            )  # [N_s,]

            probs_target = probs_cond[inds]  # [N_s, K, Cl]

            for probs_cond_i in torch.split(probs_cond, len(inputs)):
                epig_scores = epig_from_probs(probs_cond_i, probs_target)  # [B,]
                scores.append({"epig": epig_scores.cpu()})

        else:
            probs_target = probs_cond  # [N, K, Cl]

            for probs_cond_i in torch.split(probs_cond, len(inputs)):
                epig_scores = epig_from_probs_using_weights(
                    probs_cond_i, probs_target, weights
                )  # [B,]
                scores.append({"epig": epig_scores.cpu()})

        return scores.concatenate()
